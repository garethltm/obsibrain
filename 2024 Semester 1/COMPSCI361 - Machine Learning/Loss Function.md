## Definition
difference between the actual value and predicted value
$$l(y^{(i)},\hat{y}^{(i)} )$$
#compsci361example 
- $y^{(i)}$ = [1]
- $\hat{y}^{(i)}$ = [-1]
For every [[training data]] we has a [[Loss Function]] that we sum up to get an overall loss value
- For every $w$, we could have a loss value
This is used to quantify the difference between the output labels ($\hat{y}$) & true labels
#### Goal
Quantify the differences of outputs compared with labels (target)
![[empirical risk]]
#compsci361example ![[Pasted image 20240606144848.png]]
- [[Hinge Loss]]