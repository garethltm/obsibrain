Procedure monotonically decreases the [[Training error]]
- As long as not all $\huge w\tiny {L} = 0$ (prediction = 0), each tree decreases [[Training error]] 
	- continues to improve as long as the predictions are not equal to 0

## Can it overfit?
