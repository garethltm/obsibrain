- [[Decision Stumps]] have only 1 rule based on 1 feature
	- Very limited class of models: usually not very accurate for most tasks
- [[Decision Tree(s)|Decision Tree(s)]] allow sequences of splits based on multiple features
	- You can do combination of features & take all kinds of relationships into account
	- Very general class of models: can get very high accuracy
	- However, it's computationally infeasible to find the best [[Decision Tree(s)|Decision Tree(s)]]
		- too many [[Decision Tree(s)|Decision Tree(s)]] generated
- How would you build the tree?
	- Most common [[Decision Tree(s)|Decision Tree(s)]] learning algorithm in practice:
		- [[Greedy recursive splitting]]