if an [[agent(s)]] is a [[Rational Agent]], then for every [[outcome(s)]] $\huge o\tiny i\normalsize$, 
there is a real number u($\huge o\tiny i\normalsize$) such that:
- $\huge o\tiny i\normalsize$ > $\huge o\tiny j\normalsize$ if and only if u($\huge o\tiny i\normalsize$) > u($\huge o\tiny j\normalsize$) AND
- [[utility]] are linear with [[2023 Semester 2/COMPSCI367 - Artificial Intelligence/week09/Probability]]
![[Pasted image 20231026010018.png]]

### Consequences of [[(VNM-) rational]]
finding out the most preferred [[outcome(s)]]
- although preferences may seem to be complex & multifaceted, a [[Rational Agent]]'s value for an [[outcome(s)]] can be measured by a (one-dimensional) number u($\huge o\tiny i\normalsize$) - the [[utility]] of the [[outcome(s)]] $\huge o\tiny i\normalsize$
- the [[utility]] of a [[2023 Semester 2/COMPSCI367 - Artificial Intelligence/week09/Probability]] [[outcome(s)]] 
- cannot just sum up 2 [[utility]] of 2 different [[agent(s)]]
	- because if we have different [[agent(s)]] in the system $\rightarrow$ they might have outcomes that cannot be compared because we don't know in what scale they are working
- the [[utility]] of a [[2023 Semester 2/COMPSCI367 - Artificial Intelligence/week09/Probability]] [[outcome(s)]] $\huge p\tiny 1\normalsize : u (\huge o\tiny 1\normalsize),\huge p\tiny 2\normalsize : u (\huge o\tiny 2\normalsize),...,\huge p\tiny k\normalsize : u (\huge o\tiny k\normalsize)$ can be described as the linear sum
>		[[expected utility]]
- [[Linear scalability]]
- cannot just sum up 2 [[utility]] of 2 different [[agent(s)]]
	- because if we have different [[agent(s)]] in the system $\rightarrow$ they might have outcomes that cannot be compared because we don't know in what scale they are working
- [[Expected utility hypothesis]]

>	#Example 
>	![[Pasted image 20231026100336.png]]