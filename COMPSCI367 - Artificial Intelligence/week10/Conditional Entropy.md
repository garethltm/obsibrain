- Conditional [[Entropy (or self-information)]]
	- Given one variable, how much info to specify the other:
$$H(Y\ |\ X) = -\displaystyle\sum_{x\in X}\displaystyle\sum_{y\in Y}p(x,y)\ log\ p(y,x)$$
- probability of Y given X instead

- not tested in CS367